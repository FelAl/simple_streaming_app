a/simple_streaming_app/target/simple_streaming_app-1.0-SNAPSHOT-jar-with-dependencies.jar  localhost:2181 test-consumer-group test 1
16/01/07 22:24:33 INFO SparkContext: Running Spark version 1.6.0
16/01/07 22:24:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/01/07 22:24:34 WARN Utils: Your hostname, rt resolves to a loopback address: 127.0.1.1; using 192.168.0.100 instead (on interface wlan0)
16/01/07 22:24:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
16/01/07 22:24:34 INFO SecurityManager: Changing view acls to: alfe
16/01/07 22:24:34 INFO SecurityManager: Changing modify acls to: alfe
16/01/07 22:24:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(alfe); users with modify permissions: Set(alfe)
16/01/07 22:24:35 INFO Utils: Successfully started service 'sparkDriver' on port 42786.
16/01/07 22:24:35 INFO Slf4jLogger: Slf4jLogger started
16/01/07 22:24:35 INFO Remoting: Starting remoting
16/01/07 22:24:35 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.0.100:48598]
16/01/07 22:24:35 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 48598.
16/01/07 22:24:35 INFO SparkEnv: Registering MapOutputTracker
16/01/07 22:24:35 INFO SparkEnv: Registering BlockManagerMaster
16/01/07 22:24:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-adb5d154-38e3-484b-88bb-6bed71832861
16/01/07 22:24:35 INFO MemoryStore: MemoryStore started with capacity 511.5 MB
16/01/07 22:24:36 INFO SparkEnv: Registering OutputCommitCoordinator
16/01/07 22:24:36 INFO Server: jetty-8.y.z-SNAPSHOT
16/01/07 22:24:36 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
16/01/07 22:24:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/01/07 22:24:36 INFO SparkUI: Started SparkUI at http://192.168.0.100:4040
16/01/07 22:24:36 INFO HttpFileServer: HTTP File server directory is /tmp/spark-f3348a84-524b-4f6d-b2d8-627e27419a1c/httpd-4881bfb8-34e1-4c19-af6b-9a4a67a3bb3e
16/01/07 22:24:36 INFO HttpServer: Starting HTTP Server
16/01/07 22:24:36 INFO Server: jetty-8.y.z-SNAPSHOT
16/01/07 22:24:36 INFO AbstractConnector: Started SocketConnector@0.0.0.0:48099
16/01/07 22:24:36 INFO Utils: Successfully started service 'HTTP file server' on port 48099.
16/01/07 22:24:36 INFO SparkContext: Added JAR file:/home/alfe/mkdev/bigdata/simple_streaming_app/target/simple_streaming_app-1.0-SNAPSHOT-jar-with-dependencies.jar at http://192.168.0.100:48099/jars/simple_streaming_app-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1452194676640
16/01/07 22:24:36 INFO Executor: Starting executor ID driver on host localhost
16/01/07 22:24:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48363.
16/01/07 22:24:36 INFO NettyBlockTransferService: Server created on 48363
16/01/07 22:24:36 INFO BlockManagerMaster: Trying to register BlockManager
16/01/07 22:24:36 INFO BlockManagerMasterEndpoint: Registering block manager localhost:48363 with 511.5 MB RAM, BlockManagerId(driver, localhost, 48363)
16/01/07 22:24:36 INFO BlockManagerMaster: Registered BlockManager
16/01/07 22:24:37 INFO SimpleApp$: DEBUG info:localhost:2181
16/01/07 22:24:37 INFO ReceiverTracker: Starting 1 receivers
16/01/07 22:24:37 INFO ReceiverTracker: ReceiverTracker started
16/01/07 22:24:37 INFO ForEachDStream: metadataCleanupDelay = -1
16/01/07 22:24:37 INFO FlatMappedDStream: metadataCleanupDelay = -1
16/01/07 22:24:37 INFO MappedDStream: metadataCleanupDelay = -1
16/01/07 22:24:37 INFO KafkaInputDStream: metadataCleanupDelay = -1
16/01/07 22:24:37 INFO KafkaInputDStream: Slide time = 1000 ms
16/01/07 22:24:37 INFO KafkaInputDStream: Storage level = StorageLevel(false, false, false, false, 1)
16/01/07 22:24:37 INFO KafkaInputDStream: Checkpoint interval = null
16/01/07 22:24:37 INFO KafkaInputDStream: Remember duration = 1000 ms
16/01/07 22:24:37 INFO KafkaInputDStream: Initialized and validated org.apache.spark.streaming.kafka.KafkaInputDStream@3aa1abcd
16/01/07 22:24:37 INFO MappedDStream: Slide time = 1000 ms
16/01/07 22:24:37 INFO MappedDStream: Storage level = StorageLevel(false, false, false, false, 1)
16/01/07 22:24:37 INFO MappedDStream: Checkpoint interval = null
16/01/07 22:24:37 INFO MappedDStream: Remember duration = 1000 ms
16/01/07 22:24:37 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@f9b01b5
16/01/07 22:24:37 INFO FlatMappedDStream: Slide time = 1000 ms
16/01/07 22:24:37 INFO FlatMappedDStream: Storage level = StorageLevel(false, false, false, false, 1)
16/01/07 22:24:37 INFO FlatMappedDStream: Checkpoint interval = null
16/01/07 22:24:37 INFO FlatMappedDStream: Remember duration = 1000 ms
16/01/07 22:24:37 INFO FlatMappedDStream: Initialized and validated org.apache.spark.streaming.dstream.FlatMappedDStream@19cfb34e
16/01/07 22:24:37 INFO ForEachDStream: Slide time = 1000 ms
16/01/07 22:24:37 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, false, 1)
16/01/07 22:24:37 INFO ForEachDStream: Checkpoint interval = null
16/01/07 22:24:37 INFO ForEachDStream: Remember duration = 1000 ms
16/01/07 22:24:37 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@458d773f
16/01/07 22:24:37 INFO RecurringTimer: Started timer for JobGenerator at time 1452194678000
16/01/07 22:24:37 INFO JobGenerator: Started JobGenerator at 1452194678000 ms
16/01/07 22:24:37 INFO JobScheduler: Started JobScheduler
16/01/07 22:24:37 INFO StreamingContext: StreamingContext started
16/01/07 22:24:37 INFO ReceiverTracker: Receiver 0 started
16/01/07 22:24:37 INFO DAGScheduler: Got job 0 (start at main.scala:25) with 1 output partitions
16/01/07 22:24:37 INFO DAGScheduler: Final stage: ResultStage 0 (start at main.scala:25)
16/01/07 22:24:37 INFO DAGScheduler: Parents of final stage: List()
16/01/07 22:24:37 INFO DAGScheduler: Missing parents: List()
16/01/07 22:24:37 INFO DAGScheduler: Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588), which has no missing parents
16/01/07 22:24:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 40.9 KB, free 40.9 KB)
16/01/07 22:24:38 INFO JobScheduler: Added jobs for time 1452194678000 ms
16/01/07 22:24:38 INFO JobScheduler: Starting job streaming job 1452194678000 ms.0 from job set of time 1452194678000 ms
16/01/07 22:24:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.3 KB, free 54.2 KB)
16/01/07 22:24:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48363 (size: 13.3 KB, free: 511.5 MB)
16/01/07 22:24:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
-------------------------------------------
Time: 1452194678000 ms
-------------------------------------------

16/01/07 22:24:38 INFO JobScheduler: Finished job streaming job 1452194678000 ms.0 from job set of time 1452194678000 ms
16/01/07 22:24:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588)
16/01/07 22:24:38 INFO JobScheduler: Total delay: 0.105 s for time 1452194678000 ms (execution: 0.037 s)
16/01/07 22:24:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
16/01/07 22:24:38 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
16/01/07 22:24:38 INFO InputInfoTracker: remove old batch metadata: 
16/01/07 22:24:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 3011 bytes)
16/01/07 22:24:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/01/07 22:24:38 INFO Executor: Fetching http://192.168.0.100:48099/jars/simple_streaming_app-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1452194676640
16/01/07 22:24:38 INFO Utils: Fetching http://192.168.0.100:48099/jars/simple_streaming_app-1.0-SNAPSHOT-jar-with-dependencies.jar to /tmp/spark-f3348a84-524b-4f6d-b2d8-627e27419a1c/userFiles-241a0093-4257-4511-9029-751aadd8d573/fetchFileTemp969298158424695424.tmp
16/01/07 22:24:38 INFO Executor: Adding file:/tmp/spark-f3348a84-524b-4f6d-b2d8-627e27419a1c/userFiles-241a0093-4257-4511-9029-751aadd8d573/simple_streaming_app-1.0-SNAPSHOT-jar-with-dependencies.jar to class loader
16/01/07 22:24:38 INFO RecurringTimer: Started timer for BlockGenerator at time 1452194678800
16/01/07 22:24:38 INFO BlockGenerator: Started BlockGenerator
16/01/07 22:24:38 INFO BlockGenerator: Started block pushing thread
16/01/07 22:24:38 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.100:42786
16/01/07 22:24:38 INFO ReceiverSupervisorImpl: Starting receiver
16/01/07 22:24:38 INFO KafkaReceiver: Starting Kafka Consumer Stream with group: test-consumer-group
16/01/07 22:24:38 INFO KafkaReceiver: Connecting to Zookeeper: localhost:2181
16/01/07 22:24:38 INFO VerifiableProperties: Verifying properties
16/01/07 22:24:38 INFO VerifiableProperties: Property group.id is overridden to test-consumer-group
16/01/07 22:24:38 INFO VerifiableProperties: Property zookeeper.connect is overridden to localhost:2181
16/01/07 22:24:38 INFO VerifiableProperties: Property zookeeper.connection.timeout.ms is overridden to 10000
16/01/07 22:24:38 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], Connecting to zookeeper instance at localhost:2181
16/01/07 22:24:38 INFO ZkEventThread: Starting ZkClient event thread.
16/01/07 22:24:38 INFO ZooKeeper: Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
16/01/07 22:24:38 INFO ZooKeeper: Client environment:host.name=rt
16/01/07 22:24:38 INFO ZooKeeper: Client environment:java.version=1.7.0_91
16/01/07 22:24:38 INFO ZooKeeper: Client environment:java.vendor=Oracle Corporation
16/01/07 22:24:38 INFO ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
16/01/07 22:24:38 INFO ZooKeeper: Client environment:java.class.path=/home/alfe/mkdev/bigdata/compilation/spark-1.6.0/conf/:/home/alfe/mkdev/bigdata/compilation/spark-1.6.0/assembly/target/scala-2.11/spark-assembly-1.6.0-hadoop2.4.0.jar:/home/alfe/mkdev/bigdata/compilation/spark-1.6.0/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/alfe/mkdev/bigdata/compilation/spark-1.6.0/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/alfe/mkdev/bigdata/compilation/spark-1.6.0/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar
16/01/07 22:24:38 INFO ZooKeeper: Client environment:java.library.path=/opt/oracle/instantclient_12_1:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
16/01/07 22:24:38 INFO ZooKeeper: Client environment:java.io.tmpdir=/tmp
16/01/07 22:24:38 INFO ZooKeeper: Client environment:java.compiler=<NA>
16/01/07 22:24:38 INFO ZooKeeper: Client environment:os.name=Linux
16/01/07 22:24:38 INFO ZooKeeper: Client environment:os.arch=amd64
16/01/07 22:24:38 INFO ZooKeeper: Client environment:os.version=3.16.0-30-generic
16/01/07 22:24:38 INFO ZooKeeper: Client environment:user.name=alfe
16/01/07 22:24:38 INFO ZooKeeper: Client environment:user.home=/home/alfe
16/01/07 22:24:38 INFO ZooKeeper: Client environment:user.dir=/home/alfe/mkdev/bigdata/compilation/spark-1.6.0
16/01/07 22:24:38 INFO ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@6497189b
16/01/07 22:24:38 INFO ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
16/01/07 22:24:38 INFO ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
16/01/07 22:24:39 INFO JobScheduler: Starting job streaming job 1452194679000 ms.0 from job set of time 1452194679000 ms
-------------------------------------------
Time: 1452194679000 ms
-------------------------------------------

16/01/07 22:24:39 INFO JobScheduler: Added jobs for time 1452194679000 ms
16/01/07 22:24:39 INFO JobScheduler: Finished job streaming job 1452194679000 ms.0 from job set of time 1452194679000 ms
16/01/07 22:24:39 INFO MapPartitionsRDD: Removing RDD 3 from persistence list
16/01/07 22:24:39 INFO JobScheduler: Total delay: 0.019 s for time 1452194679000 ms (execution: 0.001 s)
16/01/07 22:24:39 INFO BlockManager: Removing RDD 3
16/01/07 22:24:39 INFO MapPartitionsRDD: Removing RDD 2 from persistence list
16/01/07 22:24:39 INFO BlockRDD: Removing RDD 1 from persistence list
16/01/07 22:24:39 INFO BlockManager: Removing RDD 2
16/01/07 22:24:39 INFO BlockManager: Removing RDD 1
16/01/07 22:24:39 INFO KafkaInputDStream: Removing blocks of RDD BlockRDD[1] at createStream at main.scala:20 of time 1452194679000 ms
16/01/07 22:24:39 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer()
16/01/07 22:24:39 INFO InputInfoTracker: remove old batch metadata: 
16/01/07 22:24:40 INFO JobScheduler: Added jobs for time 1452194680000 ms
16/01/07 22:24:40 INFO JobScheduler: Starting job streaming job 1452194680000 ms.0 from job set of time 1452194680000 ms
-------------------------------------------
Time: 1452194680000 ms
-------------------------------------------

16/01/07 22:24:40 INFO JobScheduler: Finished job streaming job 1452194680000 ms.0 from job set of time 1452194680000 ms
16/01/07 22:24:40 INFO JobScheduler: Total delay: 0.015 s for time 1452194680000 ms (execution: 0.001 s)
16/01/07 22:24:40 INFO MapPartitionsRDD: Removing RDD 6 from persistence list
16/01/07 22:24:40 INFO BlockManager: Removing RDD 6
16/01/07 22:24:40 INFO MapPartitionsRDD: Removing RDD 5 from persistence list
16/01/07 22:24:40 INFO BlockManager: Removing RDD 5
16/01/07 22:24:40 INFO BlockRDD: Removing RDD 4 from persistence list
16/01/07 22:24:40 INFO BlockManager: Removing RDD 4
16/01/07 22:24:40 INFO KafkaInputDStream: Removing blocks of RDD BlockRDD[4] at createStream at main.scala:20 of time 1452194680000 ms
16/01/07 22:24:40 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1452194678000 ms)
16/01/07 22:24:40 INFO InputInfoTracker: remove old batch metadata: 1452194678000 ms
16/01/07 22:24:40 INFO ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x15217ccb0e90017, negotiated timeout = 6000
16/01/07 22:24:40 INFO ZkClient: zookeeper state changed (SyncConnected)
16/01/07 22:24:40 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], starting auto committer every 60000 ms
16/01/07 22:24:40 WARN AppInfo$: Can't read Kafka version from MANIFEST.MF. Possible cause: java.lang.NullPointerException
16/01/07 22:24:40 INFO KafkaReceiver: Connected to localhost:2181
16/01/07 22:24:40 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], begin registering consumer test-consumer-group_rt-1452194678829-2da24c05 in ZK
16/01/07 22:24:40 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], end registering consumer test-consumer-group_rt-1452194678829-2da24c05 in ZK
16/01/07 22:24:40 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], starting watcher executor thread for consumer test-consumer-group_rt-1452194678829-2da24c05
16/01/07 22:24:40 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], begin rebalancing consumer test-consumer-group_rt-1452194678829-2da24c05 try #0
16/01/07 22:24:40 INFO ConsumerFetcherManager: [ConsumerFetcherManager-1452194680192] Stopping leader finder thread
16/01/07 22:24:40 INFO ConsumerFetcherManager: [ConsumerFetcherManager-1452194680192] Stopping all fetchers
16/01/07 22:24:40 INFO ConsumerFetcherManager: [ConsumerFetcherManager-1452194680192] All connections stopped
16/01/07 22:24:40 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], Cleared all relevant queues for this fetcher
16/01/07 22:24:40 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], Cleared the data chunks in all the consumer message iterators
16/01/07 22:24:40 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], Committing all offsets after clearing the fetcher queues
16/01/07 22:24:40 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], Releasing partition ownership
16/01/07 22:24:40 INFO RangeAssignor: Consumer test-consumer-group_rt-1452194678829-2da24c05 rebalancing the following partitions: ArrayBuffer(0) for topic test with consumers: List(test-consumer-group_rt-1452194678829-2da24c05-0)
16/01/07 22:24:40 INFO RangeAssignor: test-consumer-group_rt-1452194678829-2da24c05-0 attempting to claim partition 0
16/01/07 22:24:40 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], test-consumer-group_rt-1452194678829-2da24c05-0 successfully owned partition 0 for topic test
16/01/07 22:24:40 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], Consumer test-consumer-group_rt-1452194678829-2da24c05 selected partitions : test:0: fetched offset = 35: consumed offset = 35
16/01/07 22:24:40 INFO ConsumerFetcherManager$LeaderFinderThread: [test-consumer-group_rt-1452194678829-2da24c05-leader-finder-thread], Starting 
16/01/07 22:24:40 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], end rebalancing consumer test-consumer-group_rt-1452194678829-2da24c05 try #0
16/01/07 22:24:40 INFO ReceiverSupervisorImpl: Called receiver onStart
16/01/07 22:24:40 INFO ReceiverSupervisorImpl: Waiting for receiver to be stopped
16/01/07 22:24:40 INFO KafkaReceiver: Starting MessageHandler.
16/01/07 22:24:40 INFO VerifiableProperties: Verifying properties
16/01/07 22:24:40 INFO VerifiableProperties: Property client.id is overridden to test-consumer-group
16/01/07 22:24:40 INFO VerifiableProperties: Property metadata.broker.list is overridden to rt:9092
16/01/07 22:24:40 INFO VerifiableProperties: Property request.timeout.ms is overridden to 30000
16/01/07 22:24:40 INFO ClientUtils$: Fetching metadata from broker id:0,host:rt,port:9092 with correlation id 0 for 1 topic(s) Set(test)
16/01/07 22:24:40 INFO SyncProducer: Connected to rt:9092 for producing
16/01/07 22:24:40 INFO SyncProducer: Disconnecting from rt:9092
16/01/07 22:24:40 INFO ConsumerFetcherThread: [ConsumerFetcherThread-test-consumer-group_rt-1452194678829-2da24c05-0-0], Starting 
16/01/07 22:24:40 INFO ConsumerFetcherManager: [ConsumerFetcherManager-1452194680192] Added fetcher for partitions ArrayBuffer([[test,0], initOffset 35 to broker id:0,host:rt,port:9092] )
16/01/07 22:24:41 INFO JobScheduler: Added jobs for time 1452194681000 ms
-------------------------------------------16/01/07 22:24:41 INFO JobScheduler: Starting job streaming job 1452194681000 ms.0 from job set of time 1452194681000 ms

Time: 1452194681000 ms
-------------------------------------------

16/01/07 22:24:41 INFO JobScheduler: Finished job streaming job 1452194681000 ms.0 from job set of time 1452194681000 ms
16/01/07 22:24:41 INFO MapPartitionsRDD: Removing RDD 9 from persistence list
16/01/07 22:24:41 INFO JobScheduler: Total delay: 0.013 s for time 1452194681000 ms (execution: 0.001 s)
16/01/07 22:24:41 INFO BlockManager: Removing RDD 9
16/01/07 22:24:41 INFO MapPartitionsRDD: Removing RDD 8 from persistence list
16/01/07 22:24:41 INFO BlockManager: Removing RDD 8
16/01/07 22:24:41 INFO BlockRDD: Removing RDD 7 from persistence list
16/01/07 22:24:41 INFO BlockManager: Removing RDD 7
16/01/07 22:24:41 INFO KafkaInputDStream: Removing blocks of RDD BlockRDD[7] at createStream at main.scala:20 of time 1452194681000 ms
16/01/07 22:24:41 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1452194679000 ms)
16/01/07 22:24:41 INFO InputInfoTracker: remove old batch metadata: 1452194679000 ms
^C16/01/07 22:24:41 INFO SimpleApp$: ----CTRL-C HANDLING-----
16/01/07 22:24:41 INFO StreamingContext: Invoking stop(stopGracefully=false) from shutdown hook
16/01/07 22:24:41 INFO ReceiverTracker: Sent stop signal to all 1 receivers
16/01/07 22:24:41 INFO ReceiverSupervisorImpl: Received stop signal
16/01/07 22:24:41 INFO ReceiverSupervisorImpl: Stopping receiver with message: Stopped by driver: 
16/01/07 22:24:41 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], ZKConsumerConnector shutting down
16/01/07 22:24:41 INFO ConsumerFetcherManager: [ConsumerFetcherManager-1452194680192] Stopping leader finder thread
16/01/07 22:24:41 INFO ConsumerFetcherManager$LeaderFinderThread: [test-consumer-group_rt-1452194678829-2da24c05-leader-finder-thread], Shutting down
16/01/07 22:24:41 INFO ConsumerFetcherManager$LeaderFinderThread: [test-consumer-group_rt-1452194678829-2da24c05-leader-finder-thread], Stopped 
16/01/07 22:24:41 INFO ConsumerFetcherManager$LeaderFinderThread: [test-consumer-group_rt-1452194678829-2da24c05-leader-finder-thread], Shutdown completed
16/01/07 22:24:41 INFO ConsumerFetcherManager: [ConsumerFetcherManager-1452194680192] Stopping all fetchers
16/01/07 22:24:41 INFO ConsumerFetcherThread: [ConsumerFetcherThread-test-consumer-group_rt-1452194678829-2da24c05-0-0], Shutting down
16/01/07 22:24:41 INFO SimpleConsumer: Reconnect due to socket error: java.nio.channels.ClosedByInterruptException
16/01/07 22:24:41 INFO ConsumerFetcherThread: [ConsumerFetcherThread-test-consumer-group_rt-1452194678829-2da24c05-0-0], Stopped 
16/01/07 22:24:41 INFO ConsumerFetcherThread: [ConsumerFetcherThread-test-consumer-group_rt-1452194678829-2da24c05-0-0], Shutdown completed
16/01/07 22:24:41 INFO ConsumerFetcherManager: [ConsumerFetcherManager-1452194680192] All connections stopped
16/01/07 22:24:41 INFO ZkEventThread: Terminate ZkClient event thread.
16/01/07 22:24:41 INFO ZooKeeper: Session: 0x15217ccb0e90017 closed
16/01/07 22:24:41 INFO ClientCnxn: EventThread shut down
16/01/07 22:24:41 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], ZKConsumerConnector shutdown completed in 112 ms
16/01/07 22:24:41 INFO ReceiverSupervisorImpl: Called receiver onStop
16/01/07 22:24:41 INFO ReceiverSupervisorImpl: Deregistering receiver 0
16/01/07 22:24:41 ERROR ReceiverTracker: Deregistered receiver for stream 0: Stopped by driver
16/01/07 22:24:41 INFO ReceiverSupervisorImpl: Stopped receiver 0
16/01/07 22:24:41 INFO BlockGenerator: Stopping BlockGenerator
16/01/07 22:24:42 INFO JobScheduler: Added jobs for time 1452194682000 ms
16/01/07 22:24:42 INFO JobScheduler: Starting job streaming job 1452194682000 ms.0 from job set of time 1452194682000 ms
-------------------------------------------
Time: 1452194682000 ms
-------------------------------------------

16/01/07 22:24:42 INFO JobScheduler: Finished job streaming job 1452194682000 ms.0 from job set of time 1452194682000 ms
16/01/07 22:24:42 INFO MapPartitionsRDD: Removing RDD 12 from persistence list
16/01/07 22:24:42 INFO JobScheduler: Total delay: 0.011 s for time 1452194682000 ms (execution: 0.001 s)
16/01/07 22:24:42 INFO BlockManager: Removing RDD 12
16/01/07 22:24:42 INFO MapPartitionsRDD: Removing RDD 11 from persistence list
16/01/07 22:24:42 INFO BlockManager: Removing RDD 11
16/01/07 22:24:42 INFO BlockRDD: Removing RDD 10 from persistence list
16/01/07 22:24:42 INFO BlockManager: Removing RDD 10
16/01/07 22:24:42 INFO KafkaInputDStream: Removing blocks of RDD BlockRDD[10] at createStream at main.scala:20 of time 1452194682000 ms
16/01/07 22:24:42 INFO ReceivedBlockTracker: Deleting batches ArrayBuffer(1452194680000 ms)
16/01/07 22:24:42 INFO InputInfoTracker: remove old batch metadata: 1452194680000 ms
16/01/07 22:24:42 INFO RecurringTimer: Stopped timer for BlockGenerator after time 1452194682200
16/01/07 22:24:42 INFO BlockGenerator: Waiting for block pushing thread to terminate
16/01/07 22:24:42 INFO BlockGenerator: Pushing out the last 0 blocks
16/01/07 22:24:42 INFO BlockGenerator: Stopped block pushing thread
16/01/07 22:24:42 INFO BlockGenerator: Stopped BlockGenerator
16/01/07 22:24:42 INFO ReceiverSupervisorImpl: Stopped receiver without error
16/01/07 22:24:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
16/01/07 22:24:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4082 ms on localhost (1/1)
16/01/07 22:24:42 INFO DAGScheduler: ResultStage 0 (start at main.scala:25) finished in 4.104 s
16/01/07 22:24:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/01/07 22:24:42 INFO ReceiverTracker: All of the receivers have deregistered successfully
16/01/07 22:24:42 INFO ReceiverTracker: ReceiverTracker stopped
16/01/07 22:24:42 INFO JobGenerator: Stopping JobGenerator immediately
16/01/07 22:24:42 INFO RecurringTimer: Stopped timer for JobGenerator after time 1452194682000
16/01/07 22:24:42 INFO JobGenerator: Stopped JobGenerator
16/01/07 22:24:42 INFO JobScheduler: Stopped JobScheduler
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/streaming,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/streaming/batch,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static/streaming,null}
16/01/07 22:24:42 INFO StreamingContext: StreamingContext stopped successfully
16/01/07 22:24:42 INFO SparkContext: Invoking stop() from shutdown hook
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/streaming/batch/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/streaming/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
16/01/07 22:24:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
16/01/07 22:24:42 INFO SparkUI: Stopped Spark web UI at http://192.168.0.100:4040
16/01/07 22:24:42 INFO ZookeeperConsumerConnector: [test-consumer-group_rt-1452194678829-2da24c05], stopping watcher executor thread for consumer test-consumer-group_rt-1452194678829-2da24c05
16/01/07 22:24:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/01/07 22:24:42 INFO MemoryStore: MemoryStore cleared
16/01/07 22:24:42 INFO BlockManager: BlockManager stopped
16/01/07 22:24:42 INFO BlockManagerMaster: BlockManagerMaster stopped
16/01/07 22:24:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/01/07 22:24:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/01/07 22:24:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/01/07 22:24:42 INFO SparkContext: Successfully stopped SparkContext
16/01/07 22:24:42 INFO ShutdownHookManager: Shutdown hook called
16/01/07 22:24:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-f3348a84-524b-4f6d-b2d8-627e27419a1c
16/01/07 22:24:42 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/01/07 22:24:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-f3348a84-524b-4f6d-b2d8-627e27419a1c/httpd-4881bfb8-34e1-4c19-af6b-9a4a67a3bb3e
alfe@rt:~/mkdev/bigdata/compilation/spark-1.6.0$ 
alfe@rt:~/mkdev/bigdata/compilation/spark-1.6.0$ ./bin/spark-submit --class  SimpleApp --master local[4] /home/alfe/mkdev/bigdata/simple_streaming_app/target/simple_streaming_app-1.0-SNAPSHOT-jar-with-dependencies.jar  localhost:2181 test-consumer-group test 1

^[[A16/01/07 22:25:57 INFO SparkContext: Running Spark version 1.6.0
16/01/07 22:25:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/01/07 22:25:57 WARN Utils: Your hostname, rt resolves to a loopback address: 127.0.1.1; using 192.168.0.100 instead (on interface wlan0)
16/01/07 22:25:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
16/01/07 22:25:58 INFO SecurityManager: Changing view acls to: alfe
16/01/07 22:25:58 INFO SecurityManager: Changing modify acls to: alfe
16/01/07 22:25:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(alfe); users with modify permissions: Set(alfe)
16/01/07 22:25:58 INFO Utils: Successfully started service 'sparkDriver' on port 38210.
^C16/01/07 22:25:59 INFO ShutdownHookManager: Shutdown hook called
alfe@rt:~/mkdev/bigdata/compilation/spark-1.6.0$ 
